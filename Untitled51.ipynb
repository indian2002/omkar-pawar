{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62a2fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. What are the advantages of a CNN over a fully connected DNN for image classification?\n",
    "2. Consider a CNN composed of three convolutional layers, each with 3 × 3 kernels, a stride of\n",
    "2, and &quot;same&quot; padding. The lowest layer outputs 100 feature maps, the middle one outputs\n",
    "200, and the top one outputs 400. The input images are RGB images of 200 × 300 pixels.\n",
    "What is the total number of parameters in the CNN? If we are using 32-bit floats, at least how much\n",
    "RAM will this network require when making a prediction for a single instance? What about when\n",
    "training on a mini-batch of 50 images?\n",
    "3. If your GPU runs out of memory while training a CNN, what are five things you could try to\n",
    "solve the problem?\n",
    "4. Why would you want to add a max pooling layer rather than a convolutional layer with the\n",
    "same stride?\n",
    "5. When would you want to add a local response normalization layer?\n",
    "6. Can you name the main innovations in AlexNet, compared to LeNet-5? What about the main\n",
    "innovations in GoogLeNet, ResNet, SENet, and Xception?\n",
    "7. What is a fully convolutional network? How can you convert a dense layer into a\n",
    "convolutional layer?\n",
    "8. What is the main technical difficulty of semantic segmentation?\n",
    "9. Build your own CNN from scratch and try to achieve the highest possible accuracy on MNIST.\n",
    "10. Use transfer learning for large image classification, going through these steps:\n",
    "a. Create a training set containing at least 100 images per class. For example, you could\n",
    "classify your own pictures based on the location (beach, mountain, city, etc.), or\n",
    "alternatively you can use an existing dataset (e.g., from TensorFlow Datasets).\n",
    "b. Split it into a training set, a validation set, and a test set.\n",
    "c. Build the input pipeline, including the appropriate preprocessing operations, and\n",
    "optionally add data augmentation.\n",
    "d. Fine-tune a pretrained model on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6740ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Advantages of CNN over fully connected DNN for image classification:\n",
    "   - **Translation invariance**: CNNs can detect patterns regardless of their location in the image due to the use of shared weights in convolutional layers.\n",
    "   - **Parameter efficiency**: CNNs exploit spatial correlations in images, resulting in fewer parameters compared to fully connected DNNs.\n",
    "   - **Hierarchical feature learning**: CNNs learn hierarchical representations of features, capturing low-level features in early layers and high-level features in deeper layers.\n",
    "   - **Better handling of large inputs**: CNNs can efficiently process large input images without requiring massive computational resources compared to fully connected DNNs.\n",
    "\n",
    "2. Total number of parameters in the CNN:\n",
    "   - Each convolutional layer with 3x3 kernels and 100, 200, and 400 feature maps respectively:\n",
    "     - Parameters per layer = (3 * 3 * input_channels + 1) * output_channels\n",
    "     - Parameters for the first layer = (3 * 3 * 3 + 1) * 100 = 2800\n",
    "     - Parameters for the second layer = (3 * 3 * 100 + 1) * 200 = 180200\n",
    "     - Parameters for the third layer = (3 * 3 * 200 + 1) * 400 = 720400\n",
    "   - Total parameters = 2800 + 180200 + 720400 = 903400\n",
    "\n",
    "   RAM required for prediction:\n",
    "   - Total RAM = (number of parameters * 32 bits) / 8\n",
    "   - RAM for prediction = (903400 * 32) / 8 ≈ 3.4 MB\n",
    "\n",
    "   RAM required for training on a mini-batch of 50 images:\n",
    "   - RAM for training = RAM for prediction * 50 ≈ 170 MB\n",
    "\n",
    "3. If GPU runs out of memory while training a CNN, you could try:\n",
    "   - Reducing batch size.\n",
    "   - Reducing model complexity (e.g., reducing the number of layers or feature maps).\n",
    "   - Using mixed precision training.\n",
    "   - Increasing GPU memory by using a GPU with more memory.\n",
    "   - Using data parallelism across multiple GPUs.\n",
    "\n",
    "4. Max pooling layers are used to downsample feature maps and reduce computational complexity while maintaining important features. Adding a convolutional layer with the same stride would increase the number of parameters and computations, leading to higher memory and computational requirements.\n",
    "\n",
    "5. Local Response Normalization (LRN) layers are used to normalize activations within local neighborhoods, encouraging competition between adjacent neurons and enhancing the contrast between features. They are typically added after convolutional layers in CNN architectures to improve generalization and robustness.\n",
    "\n",
    "6. Main innovations:\n",
    "   - **AlexNet**: Introduced the concept of deep CNNs with multiple convolutional layers, ReLU activation, dropout regularization, and GPU acceleration.\n",
    "   - **GoogLeNet**: Introduced the inception module with parallel convolutional operations of different sizes to capture features at multiple scales efficiently.\n",
    "   - **ResNet**: Introduced residual connections to address the vanishing gradient problem, enabling training of very deep networks (hundreds of layers).\n",
    "   - **SENet (Squeeze-and-Excitation Networks)**: Introduced the attention mechanism by adaptively recalibrating channel-wise feature responses.\n",
    "   - **Xception**: Introduced depthwise separable convolutions to reduce the number of parameters and computations while maintaining expressive power.\n",
    "\n",
    "7. Fully Convolutional Network (FCN) replaces dense layers with convolutional layers, allowing the network to accept input of any size and produce output feature maps with spatial dimensions. To convert a dense layer into a convolutional layer, you set the kernel size equal to the input size and the number of filters equal to the number of neurons in the dense layer.\n",
    "\n",
    "8. The main technical difficulty of semantic segmentation is achieving accurate pixel-level predictions while preserving spatial information and handling class imbalance, occlusions, and varying object scales within an image.\n",
    "\n",
    "9. Building a CNN from scratch for MNIST classification:\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define CNN architecture\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Load MNIST data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Reshape images for CNN input\n",
    "train_images = train_images.reshape((-1, 28, 28, 1))\n",
    "test_images = test_images.reshape((-1, 28, 28, 1))\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=5, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)\n",
    "```\n",
    "\n",
    "10. Transfer learning for large image classification:\n",
    "   - (a) Collect or use an existing dataset containing at least 100 images per class.\n",
    "   - (b) Split the dataset into training, validation, and test sets.\n",
    "   - (c) Build the input pipeline, preprocess images, and optionally apply data augmentation techniques.\n",
    "   - (d) Fine-tune a pretrained model (e.g., ResNet, Inception, VGG) on the training set and evaluate its performance on the validation set. Adjust hyperparameters and continue fine-tuning until satisfactory performance is achieved. Finally, evaluate the model on the test set to assess its generalization ability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
