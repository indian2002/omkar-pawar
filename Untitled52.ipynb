{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c946303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Can you think of a few applications for a sequence-to-sequence RNN? What about a\n",
    "sequence-to-vector RNN, and a vector-to-sequence RNN?\n",
    "2. How many dimensions must the inputs of an RNN layer have? What does each dimension\n",
    "represent? What about its outputs?\n",
    "3. If you want to build a deep sequence-to-sequence RNN, which RNN layers should\n",
    "have return_sequences=True? What about a sequence-to-vector RNN?\n",
    "4. Suppose you have a daily univariate time series, and you want to forecast the next seven\n",
    "days. Which RNN architecture should you use?\n",
    "5. What are the main difficulties when training RNNs? How can you handle them?\n",
    "6. Can you sketch the LSTM cell’s architecture?\n",
    "7. Why would you want to use 1D convolutional layers in an RNN?\n",
    "8. Which neural network architecture could you use to classify videos?\n",
    "9. Train a classification model for the SketchRNN dataset, available in TensorFlow Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bada32a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Applications for different types of RNNs:\n",
    "   - Sequence-to-sequence RNN: Language translation, text summarization, speech recognition.\n",
    "   - Sequence-to-vector RNN: Sentiment analysis, document classification, image captioning.\n",
    "   - Vector-to-sequence RNN: Image generation from captions, music generation from a melody.\n",
    "\n",
    "2. Inputs of an RNN layer:\n",
    "   - The inputs of an RNN layer must have three dimensions: `(batch_size, timesteps, input_features)`.\n",
    "   - Each dimension represents:\n",
    "     - `batch_size`: The number of sequences in each batch.\n",
    "     - `timesteps`: The length of each sequence or the number of time steps in the sequence.\n",
    "     - `input_features`: The number of features or input dimensions at each time step.\n",
    "\n",
    "   Outputs of an RNN layer:\n",
    "   - The outputs of an RNN layer also have three dimensions: `(batch_size, timesteps, output_features)`.\n",
    "   - Each dimension represents:\n",
    "     - `batch_size`: The same as the input.\n",
    "     - `timesteps`: The same as the input or the number of time steps in the output sequence.\n",
    "     - `output_features`: The number of output dimensions or features at each time step.\n",
    "\n",
    "3. In a deep sequence-to-sequence RNN:\n",
    "   - RNN layers in the encoder should have `return_sequences=True` to pass the entire sequence to the next layer.\n",
    "   - RNN layers in the decoder should also have `return_sequences=True` to generate sequences at each time step.\n",
    "\n",
    "   In a sequence-to-vector RNN:\n",
    "   - The last RNN layer should have `return_sequences=False` (by default) to output a single vector representing the entire sequence.\n",
    "\n",
    "4. For forecasting the next seven days from a daily univariate time series, you should use a sequence-to-sequence RNN architecture. The output of the network would be a sequence of length seven, where each time step corresponds to the forecast for each day.\n",
    "\n",
    "5. Main difficulties when training RNNs:\n",
    "   - Vanishing or exploding gradients: Long sequences or deep architectures can lead to vanishing or exploding gradients during backpropagation.\n",
    "   - Memory limitations: RNNs suffer from memory constraints due to the need to store activations for each time step.\n",
    "   - Training instability: RNNs can be sensitive to hyperparameters and suffer from training instabilities like gradient saturation.\n",
    "\n",
    "   Handling methods:\n",
    "   - Use gradient clipping to prevent exploding gradients.\n",
    "   - Use techniques like LSTM or GRU cells to alleviate vanishing gradient problems.\n",
    "   - Apply regularization techniques such as dropout or recurrent dropout to prevent overfitting.\n",
    "   - Use batch normalization to stabilize training and improve convergence.\n",
    "\n",
    "6. LSTM cell architecture:\n",
    "\n",
    "```\n",
    "       ________\n",
    "      |        |\n",
    "Input →| LSTM   |→ Output\n",
    "      |________|\n",
    "         ↑  ↑\n",
    "         |  |\n",
    "     Hidden state\n",
    "```\n",
    "\n",
    "7. 1D convolutional layers in an RNN:\n",
    "   - Can capture local patterns or features within sequences effectively.\n",
    "   - Provide a computationally efficient way to learn hierarchical representations.\n",
    "   - Can be used as an alternative to recurrent layers or in conjunction with them to capture both local and long-range dependencies.\n",
    "\n",
    "8. A neural network architecture for classifying videos:\n",
    "   - Convolutional Neural Networks (CNNs) for feature extraction from video frames.\n",
    "   - Recurrent Neural Networks (RNNs) or Long Short-Term Memory (LSTM) networks for capturing temporal dependencies across video frames.\n",
    "   - Optionally, attention mechanisms can be incorporated to focus on relevant video segments.\n",
    "\n",
    "9. To train a classification model for the SketchRNN dataset available in TensorFlow Datasets, you would need to:\n",
    "   - Load the dataset using TensorFlow Datasets.\n",
    "   - Preprocess the data and prepare it for training, including normalization and splitting into training and validation sets.\n",
    "   - Define a suitable neural network architecture, such as a CNN or RNN, for classification.\n",
    "   - Compile the model with an appropriate loss function and optimizer.\n",
    "   - Train the model on the training data.\n",
    "   - Evaluate the model's performance on the validation set and tune hyperparameters if necessary.\n",
    "   - Finally, test the model on the test set to assess its generalization performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
